Thinking about overfitting, cross validation, and using the caret package. 

[Slides](https://github.com/natelangholz/stat412-advancedregression/blob/master/week-6/slides-week-6.pdf)

Some additional readings.

[An Empirical Comparison of Supervised Learning Algorithms](https://www.cs.cornell.edu/%7Ecaruana/ctp/ct.papers/caruana.icml06.pdf)

[Interesting visual outlining tree models](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/)

Maybe the most well known predictive modeling exercise is the $1 million Netflix prize. Not only is it widely known that Netflix did not use the winning model because of engineering costs due to computational complexity but Netflix also had to settle a multi-million dollar lawsuit for privacy invasion.

[Netflix never used its $1 Million Algorithm due to engineering costs](https://www.wired.com/2012/04/netflix-prize-costs/)

[The Netflix Prize](https://www.thrillist.com/entertainment/nation/the-netflix-prize)
