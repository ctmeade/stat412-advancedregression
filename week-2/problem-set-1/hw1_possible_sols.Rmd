
  ### The Sound of Gunfire, Off in the Distance
  Our first dataset this week comes from a study of the causes of civil wars.[^1] The data
can be read into from a csv posted online by using the following command.

```{r}
war <- read.csv("http://www.stat.cmu.edu/~cshalizi/uADA/15/hw/06/ch.csv", row.names = 1)
```

Every row of the data represents a combination of a country and of a five year interval — the
first row is Afghanistan, 1960, really meaning Afghanistan, 1960–1965. The 
variables are:
  
  - The country name;
- The year;
- An indicator for whether a civil war began during that period: 1 indicates a 
civil war has begun, the code of NA means an on-going civil war, 0 means peace.
- Exports, really a measure of how dependent the country’s economy is on commodity exports;
- Secondary school enrollment rate for males, as a percentage;
- Annual growth rate in GDP;
- An index of the geographic concentration of the country’s population (which would be 1 if the entire population lives in one city, and 0 if it evenly spread across the territory);
- The number of months since the country’s last war or the end of World War II, whichever is more recent;
- The natural logarithm of the country’s population;
- An index of social “fractionalization”, which tries to measure how much the
country is divided along ethnic and/or religious lines;
- An index of ethnic dominance, which tries to measure how much one ethnic
group runs affairs in the country.

Some of these variables are NA for some countries.

### 1
**Estimate**: Fit a logistic regression model for the start of civil war on all other variables except country and year (yes, this makes some questionable assumptions about independent observations); include a quadratic term for exports. Report the coefficients and their standard errors, together with R’s p-values. Which ones are found to be significant at the 5% level?

**Solution**
Suppose we drop all missing cases.  It turns out R will do this for us.
```{r}
set.seed(601)
tdat <- cbind(war[,-c(1:2)],war[,"exports"]^2)
colnames(tdat)[10] <- c("exports2")
tdat <- na.omit(tdat)  ## this drops a row if any of the variables is missing
namod <- glm(start~.,data=tdat,family="binomial",model= T)
summary(namod)
AIC(namod)
```
We can simply extract the model matrix from the glm object for future use.
```{r}
head(namod$model)
```
Suppose we decide to impute missing values among the predictors.   The Amelia package does this for us.  See https://gking.harvard.edu/files/gking/files/amelia_jss.pdf for details.  This code snippet imputes 5 datasets and stores the model fit on each dataset. 
```{r}
set.seed(601)
tdat <- cbind(war[,-c(1:2)],war[,"exports"]^2)
colnames(tdat)[10] <- c("exports2")
tdat <- na.omit(tdat)
namod <- glm(start~.,data=tdat,family="binomial")

library(Amelia)
M <- 5
## i'll drop observations values for start and any country missing more 20% of its data
inds <- which(is.na(war[,"start"])==F) 
tmp <- by(war[inds,],war[inds,"country"],function(x){sum(is.na(x)==T)/(sum(is.na(x)==T)+sum(is.na(x)==F))})
mdat <- subset(war[inds,],country%in%names(which(sapply(tmp,function(x){x<.05}))))

#adat <- cbind(war[,-c(1:2)],war[,"exports"]^2)
imputed_war <- amelia(mdat[,-3],m=M,ts="year",cs="country")
attributes(imputed_war)
head(imputed_war$imputations[[1]])
mod <- list()
for (m in c(1:M)){
  mydat <- cbind(mdat[,"start"],imputed_war$imputations[[m]][,-c(1:2)],imputed_war$imputation[[m]][,"exports"]^2)
  colnames(mydat)[c(1,10)] <- c("start","exports2")
  #mydat <- na.omit(mydat)
  mod[[m]] <- glm(start~.,data=mydat,family="binomial")
  summary(mod[[m]])
}
```
The parameter estimates and their variances can be combined across imputations to get
$$\theta_{MI}=\frac{1}{M}\sum_m \theta_m$$
```{r}
avgcoefs <- colMeans(do.call(rbind,lapply(mod,coef)))
print(avgcoefs)
```





### 2
**Interpretation**: All parts of this question refer to the logistic regression model you just fit.

1. What is the model’s predicted probability for a civil war in India in the period beginning 1975? What probability would it predict for a country just like India in 1975, except that its male secondary school enrollment rate was 30 points higher? What probability would it predict for a country just like India in 1975, except that the ratio of commodity exports to GDP was 0.1 higher?

```{r}
india.1975 <- war[which(war$country=="India" & war$year==1975),]
plogis(coef(namod)%*%unlist(c(1,india.1975[-c(1:3)],india.1975[4]^2)))
```
The model’s predicted probability for a civil war in India in the period beginning 1975 is 35.04%.
```{r}
plogis(coef(namod)%*%(unlist(c(1,india.1975[-c(1:3)],india.1975[4]^2))+ c(0,0,30,rep(0,7))))

```
If everything else remains the same for India in the period beginning 1975, but the male secondary school enrollment rate increases by 30 percentage points, then the predicted probability of war decreases by more than half to 17.31%.
```{r}
tmp <- unlist(c(1,india.1975[-c(1:3)])) + c(0,.1,rep(0,7))
tmp <- c(tmp,tmp[2]^2)
plogis(coef(namod)%*%tmp)
```
If everything else remains the same for India in the period beginning 1975, except the ratio of commodity exports to GDP was 0.1 higher, then the predicted probability of war almost doubles to 69.61%.

2. What is the model’s predicted probability for a civil war in Nigeria in the period beginning 1965? What probability would it predict for a country just like Nigeria in 1965, except that its male secondary school enrollment rate was 30 points higher? What probability would it predict for a country just like Nigeria in 1965, except that the ratio of commodity exports to GDP was 0.1 higher?

```{r}
nigeria.1965 <-  war[which(war$country=="Nigeria" & war$year==1965),]
plogis(coef(namod)%*%unlist(c(1,nigeria.1965[-c(1:3)],nigeria.1965[4]^2)))
```
The model’s predicted probability for a civil war in Nigeria in the period beginning 1965 is 17.10%.
```{r}
plogis(coef(namod)%*%(unlist(c(1,nigeria.1965[-c(1:3)],nigeria.1965[4]^2))+ c(0,0,30,rep(0,7))))
```
If everything else remains the same for Nigeria in the period beginning 1965, but the male secondary school enrollment rate increases by 30 percentage points, then the predicted probability of war decreases by more than half to 7.41%.
```{r}
tmp <- unlist(c(1,nigeria.1965[-c(1:3)])) + c(0,.1,rep(0,7))
tmp <- c(tmp,tmp[2]^2)
plogis(coef(namod)%*%tmp)
```
If everything else remains the same for Nigeria in the period beginning 1965, except the ratio of commodity exports to GDP was 0.1 higher, then the predicted probability of war almost doubles to 33.10%.

3. In the parts above, you changed the same predictor variables by the same amounts. If you did your calculations properly, the changes in predicted probabilities are not equal. Explain why not. (The reasons may or may not be the same for the two variables.)

**Solution (by James Lepore)**
he primary reason that the changes in predicted probabilities are not equal in magnitude is that the coefficients of a logistic regression model with a logit link measure changes in log odds. To put it in perhaps a simpler light, when the coefficient of a logit is small in magnitude (i.e. less < .1), the coefficient can actually be thought of as an approximation of the percent change for every one unit increase. The percent change in predicted probability is obviously dependent on the baseline and starting input values. India in 1975 (35.04%) and Nigeria in 1965 (17.09%) are starting from two very different places, and the male secondary school enrollment rates are also quite different (36% for India versus 7% for Nigeria). This is in contrast to a linear regression where the coefficients measure the linear effect of a one unit increase in the input (meaning the base and starting value are irrelevant). That being said, even in a regular regression model we would still observe a different magnitude change in predicted probabilites for equivalent increases in the ratio of commodity exports to GDP. The reasoning why is quite similar. If you recall, we modeled the exports variable with an additional quadratic term, meaning the linear interpretation of the coefficients continues to no longer be applicable because once again the starting input values will matter. For example, a .1 increase from .026 (India 1975) will result in a .0152 increase in the quadratic input. Whereas a .1 increase from .123 (Nigeria 1965) will result in a .0346 quadratic input (more than double the magnitude).


### 3
**Confusion**: Logistic regression predicts a probability of civil war for each country and period. Suppose we want to make a definite prediction of civil war or not, that is, to classify each data point. The probability of misclassification is minimized by predicting war if the probability is ≥ 0.5, and peace otherwise.

1. Build a 2 × 2 *confusion matrix* (a.k.a. “classification table” or “contigency table”) which counts: the number of outbreaks of civil war correctly predicted by the logistic regression; the number of civil wars not predicted by the model; the number of false predictions of civil wars; and the number of correctly predicted absences of civil wars. (Note that some entries in the table may be zero.)
2. What fraction of the logistic regression’s predictions are incorrect, i.e. what is the misclassification rate? (Note that this is if anything too kind to the model, since it’s looking at predictions to the same training data set).
3. Consider a foolish (?) pundit who always predicts “no war”. What fraction of the pundit’s predictions are correct on the whole data set? What fraction are correct on data points where the logistic regression model also makes a prediction?

**Solution**
```{r}
confuse <- function(x,xhat){
  cm <- matrix(c(sum(x==1&xhat==1),
           sum(x==0&xhat==1),
           sum(x==1&xhat==0),
           sum(x==0&xhat==0)),2,2,byrow=T)
  ac <- (sum(x==1&xhat==1)+sum(x==0&xhat==0))/length(x)
  list(cm=cm,ac=ac)
}
### test our dataset with all missing values removed
print(confuse(namod$model[,1],as.numeric(fitted.values(namod)>.5)))
print(confuse(namod$model[,1],rep(0,nrow(namod$model))))
print(confuse(war[inds,"start"],rep(0,length(inds))))
```
The pundit achieves 93% accuracy on both datasets.  Because war is rare, the pundit outperforms the logistic regression in terms of predictive accuracy.

### 4
**Comparison**: Since this is a classification problem with only two classes, we can compare Logistic Regression right along side Discriminant Analysis.

1. Fit an LDA model using the same predictors that you used for your logistic regression model. What is the training misclassification rate?
2. Fit a QDA model using the very same predictors. What is the training misclassification rate? 
3. How does the prediction accuracy of the three models compare? Why do you think this is?

**Solution**
```{r}
library(MASS)
library(e1071)
library(nnet)

trset <- sample(c(1:1167),750,replace=F)
ttset <- setdiff(c(1:1167),trset)
lda_mod <- qda_mod <- svm_mod <- nnet_mod <- knn_mod <- rf_mod <- list()
for (m in c(1:M)){
  mydat <- cbind(mdat[,"start"],imputed_war$imputations[[m]][,-c(1:2)],imputed_war$imputation[[m]][,"exports"]^2)
  colnames(mydat)[c(1,10)] <- c("start","exports2")
  mydat <- na.omit(mydat)
  lda_mod[[m]] <- lda(start~.,data=mydat)
  qda_mod[[m]] <- qda(start~.,data=mydat)
  svm_mod[[m]] <- svm(as.factor(start)~.,data=mydat,probability=T)
  nnet_mod[[m]] <- nnet(as.factor(start)~.,data=mydat,size=10,skip=F)
}
```
Let's generate predictions for the models.
```{r}
confuse <- function(x,xhat){
  cm <- matrix(c(sum(x==1&xhat==1),
           sum(x==0&xhat==1),
           sum(x==1&xhat==0),
           sum(x==0&xhat==0)),2,2,byrow=T)
  ac <- (sum(x==1&xhat==1)+sum(x==0&xhat==0))/length(x)
  list(cm=cm,ac=ac)
}
### test our dataset with all missing values removed
print(confuse(tdat[,"start"],as.numeric(fitted.values(namod)>.5)))

for (m in c(1:M)){
  mydat <- cbind(mdat[,"start"],imputed_war$imputations[[m]][,-c(1:2)],imputed_war$imputation[[m]][,"exports"]^2)
  colnames(mydat)[c(1,10)] <- c("start","exports2")
  #mydat <- na.omit(mydat)
  ## try each of the imputed models on the original data
  print(confuse(namod$model[,1],as.numeric(predict(mod[[m]],namod$model[,-1],type="response")>.5)))
  print(confuse(namod$model[,1],as.numeric(predict(lda_mod[[m]],namod$model[,-1])$class)-1))
  print(confuse(namod$model[,1],as.numeric(predict(qda_mod[[m]],namod$model[,-1])$class)-1))
  
  #print(confuse(mydat[,"start"],as.numeric(as.character(predict(svm_mod[[m]],mydat)))))
  #print(confuse(mydat[,"start"],as.numeric(as.character(predict(nnet_mod[[m]],mydat,type="class")))))
}

## Now try using the averaged coefficients on the orginial data

p2 <- avgcoefs %*% t(cbind(rep(1,nrow(tdat)),namod$model[,-1]))
p2 <- plogis(p2)
print(confuse(namod$model[,1],as.numeric(p2)>.5))
  
```
We see that imputation improved predictive accuracy by a modest amount (93% to 93.6%).  Quadratic Discriminant Analysis does the worst - it overpredicts conflict.  This suggests the assumptions for QDA; the covariance matrices of data from the two populations may not be different.
```{r}
cov(namod$model[namod$model[,1]==1,-1]);cov(namod$model[namod$model[,1]==0,-1])
```


* * *
  
**Challenge problem**: Using the code available on the week 6 page, construct an ROC curve for your logistic regression model. For an extra challenge, plot the ROC curves of all three models on the same plot.

**Solution**:
The ROC curve is created by plotting the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings.  That is, compute
$${\mathit {TPR}(t)}={\mathit {TP}(t)}/P$$
and $${\mathit {FPR}(t)}={\mathit {FP}(t)}/N$$ for all $t$ in a sequence of threshold values from zero to one. 

```{r}
myroc <- function(x,xhat,myt){
  tmp <- NULL
  for (j in c(1:length(myt))){
    fpr <- sum(x==0&xhat>myt[j])/sum(x==0)
    tpr <- sum(x==1&xhat>myt[j])/sum(x==1)
    tmp <- rbind(tmp,c(fpr,tpr))
  }
  return(tmp)
}
#plot(myroc(mydat[,"start"],as.numeric(fitted.values(mod[[m]])),seq(from=0,to=1,by=.01)),
#     xlab="FPR",ylab="TPR",pch=20)
library(ROCR)
pred0 <- prediction( namod$fitted.values, namod$model[,1])
pred <- prediction( as.numeric(predict(mod[[1]],namod$model[,-1])), namod$model[,1])
pred2 <- prediction( as.numeric(predict(lda_mod[[1]],namod$model[,-1])$posterior[,2]), namod$model[,1])
pred3 <- prediction( as.numeric(predict(qda_mod[[1]],namod$model[,-1])$posterior[,2]), namod$model[,1])

pred4 <-  prediction(t(p2),namod$model[,1])
#pred4 <- prediction( as.numeric(as.character(attr(predict(svm_mod[[m]],namod$model[,-1],probability = T),"probabilities")[,2])), namod$model[,1])
#pred5 <- prediction( predict(nnet_mod[[m]],namod$model[,-1],type = "raw"), namod$model[,1])
perf0 <- performance(pred0,"tpr","fpr")
performance(pred0,"auc")
perf <- performance(pred,"tpr","fpr")
performance(pred,"auc")
perf2 <- performance(pred2,"tpr","fpr")
performance(pred2,"auc")
perf3 <- performance(pred3,"tpr","fpr")
performance(pred3,"auc")
perf4 <- performance(pred4,"tpr","fpr")
performance(pred4,"auc")
#perf5 <- performance(pred5,"tpr","fpr")

plot(perf0,col="black",lty=1,lwd=1.5)
plot(perf,add=T,col="green",lty=2,lwd=1.5)
plot(perf2,add=T,col="blue",lty=3,lwd=1.5)
plot(perf3,add=T,col="red",lty=4,lwd=1.5)
plot(perf4,add=T,col="purple",lty=5,lwd=1.5)


legend("bottomright",c("logit (no impute)","logit","lda","qda","logit (averaged)"),lty=c(1,2,3,4,5),col=c("black","green","blue","red","purple"))
```
We see that QDA actually has the most area under the curve.

### 6
**Confusion**:

Fit a logistic regression using y as the response with x1 and x2 as indepedent variables. Does anything strange happen? Explain.
```{r}
y<- c(0,0,0,0,1,1,1,1)
x1<-c(1,2,3,3,5,6,10,11)
x2<-c(3,2,-1,-1,2,4,1,0)
res <- glm(y~x1+x2,family="binomial")
summary(res)
```
The cases have been divided perfectly; there is no uncertainty to quantify.  That is,  
$$x_1>3\implies y=1.$$
We cannot find the MLE because the parameter associated with $x_1$ will be infinite.  Hence inference from the model cannot be used.  In fact, there is no need to fit a model.

[^1]: Based on an exercise of Cosmo Shalizi's that uses data from Collier, Paul and Anke Hoeffler (2004). *Greed and Grievance in Civil War.* Oxford Economic Papers, 56: 563–595. URL: http://economics.ouls.ox.ac.uk/12055/1/2002-01text.pdf.
